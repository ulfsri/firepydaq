firepydaq.utilities.PostProcessing
==================================

.. py:module:: firepydaq.utilities.PostProcessing


Classes
-------

.. autoapisummary::

   firepydaq.utilities.PostProcessing.PostProcessData


Module Contents
---------------

.. py:class:: PostProcessData(**files)

   An object that processes data based on the config and formulae file

   Setting up how the post processing will be done,
   as a utility or use in the dash app

   :keyword jsonpath: If the Input keyword is 'jsonpath', it must have a path
                      to the json file for the corresponding experiment.
   :kwtype jsonpath: str
   :keyword datapath: Path to the data `.parquet file`
   :kwtype datapath: str
   :keyword configpath: Path to the config .csv file
   :kwtype configpath: str
   :keyword formulaepath: Path to the formulae .csv file
   :kwtype formulaepath: str (Optional)

   .. note::

      Will accept a maximum of 3 keyword args

      Alternatively (if not using `jsonpath`), the input keyword must be
      at least 'datapath' and 'configpath'.
      Input keyword can be 'datapath', 'configpath', and 'formulaepath'.

      **The input must have reference to data and config paths**

   .. attribute:: path_dict

      Contains a dictionary that maps
      `datapath`,`configpath`, and `formulaepath`.

      The items of the keys are read as `polars.DataFrame`

      `datapath` can be path to live data, or data collected
      after an experiment, or randomly created numpy array
      to validate formulae before acquisition begins.

      `configpath` can be path to the configuration file
      for the NI hardware that uses ni-daqmx driver.

      `formulaepath` can be a path to the formulae file. Optionally,
      if processing formulae needs to be skipped,
      the path is passed as an either an empty string ('').

      Formulae file should use the variables defined in the `Label`
      column of the config file. The formulae file will be
      processed in the order that the formulae appears,
      from the topmost row to the bottom.

      :type: dict

   .. attribute:: data_dict

      'data': polars.DataFrame,
      'config': polars.DataFrame,
      'formulae': polars.DataFrame

      :type: dict

   .. attribute:: All_chart_info

      A polars DataFrame concatenated using
      the config and the formulae file.
      Excludes values in "Chart" column
      in config or formulae file
      that contains either "Intermediate" or "Constant".

      :type: polars.DataFrame


   .. py:method:: MergeConfig_Formulae()

      Will merge config and formulae file csvs
      into a polars DataFrame.

      Creates the attribute All_chart_info.



   .. py:method:: UpdateData(dump_output=True)

      A method to update the processed data
      using the initiated path configs

      Creates the attribute df_processed: `polars.DataFrame`

          If `dump_output = True` (Default), A new file having the name
          `self.path_dict['datapath'].split('.parquet')[0]+'_PostProcessed.parquet'` will be created.  # noqa E501

      :param dump_output: Default `dump_outut = True`

                          `True`: Processed data will be saved at the
                          location where the data is read from.

                          `False`: Processed data will not save the processed data
      :type dump_output: bool, Optional



   .. py:method:: ScaleData()

      Method to scale the raw data.

      Data is scaled assuming linear scaling from
      `ScaleMax` and `ScaleMin` for the corresponding
      analog input of `AIRangeMax` and `AIRangeMin`.

      For each label in the config file, a corresponding
      ``min_AI`` and `max_AI` are read,
      which correspond to `AIRangeMin` and `AIRangeMax` respectively.
      `ScaleMax` and `ScaleMin` are also used for this scaling.
      `ScaleMin` is the offset in this linear correlation.

      `Unit_per_V` variable is created which is the ratio of the
      differrence between the `ScaleMax` and `ScaleMin`,
      to the difference between `AIRangeMax` and `AIRangeMin`
      Scaled data, scaled_data is then obtained as follows,
          `scaled_data` = (`raw_data` - `min_AI`)*`unit_per_V` + `ScaleMin`




   .. py:method:: ExecEqn(lhs, rhs)

      Method to execute an equation of the form lhs = rhs

      This will set the lhs string as an attribute for this object

      :param lhs: Left-hand side of the equation.
                  This variable will be created upon execution
      :type lhs: string
      :param rhs: Right-hand side of the equation.
                  Express the rhs in the form of what
                  can be interpreted by python.
                  Use formulae_dictoinary in DAQUtils to guide with that.
      :type rhs: string



   .. py:method:: ParseFormulae()

      A method to parse the formulae listed in a csv file.

      This function can be used to test the formulae file for sanity
      before running the dash.

      Needs to have scaled data before calling this method.



